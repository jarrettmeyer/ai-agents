# If you are running locally with Ollama, try "llama3.2".
LLM_MODEL="openai:gpt-4o"

# You can comment out this line if you are using OpenAI.
OLLAMA_HOST="http://localhost:11434/v1"

# Setting this value will allow you to use the OpenAI API.
# Comment out this line if you want to run Ollama locally.
OPENAI_API_KEY=""

# Request a free API key from https://geocode.maps.co/.
GEOCODE_API_KEY=""

#
GEOCODE_API_ENDPOINT="https://geocode.maps.co/search"

# Request a free API key from https://www.tomorrow.io/weather-api/.
WEATHER_API_KEY=""

#
WEATHER_API_ENDPOINT="https://api.tomorrow.io/v4/weather/realtime"
